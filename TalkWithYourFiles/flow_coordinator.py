import logging
from dotenv import load_dotenv
from file_handlers import FileHandlerFactory
from text_processor import DefaultTextProcessor
from qa_chain import QAChainRunner
from parameter_controller import ParameterController
from typing import List, Optional, Tuple, Dict, IO

"""
This file, flow_coordinator.py, serves as a central coordination module within the application. It acts as a bridge between user interface & underlying functionalities of other modules.
It is designed to make the application maintainable & flexible by not being dependent on a certain framework. As long as the logic & functionalities are provided here the run function will serve its purpose.

KEY FEATURES:
Loading Environment Variables: 
The load_dotenv() function is called to load the environment variables defined in the project's .env file. This ensures that sensitive or configurable information is securely accessed by the application.

File Handling: 
The FileHandlerFactory class from file_handlers.py is utilized to obtain the appropriate file handler based on the file type. The selected handler is then used to read the file's contents. 

Text Processing:
The DefaultTextProcessor class from text_processor.py provides text processing functionality, such as splitting text into chunks and creating embeddings.

Question-Answering Chain Execution: 
The QAChainRunner class from qa_chain.py is instantiated, representing the question-answering chain runner. This class uses an LLM to execute the chain. The get_relative_chunks() method finds the most relevant chunks in the knowledge base for a given user question, and the run_chain() method runs the question-answering chain on the provided documents and question.

Param Controller:
Parameter Controller class, an instance of it is passed to the flow coordinator, text processor and the chain runner have control over the behaviour of the application.

Logging and Error Handling: 
The logging module is used to provide informative log messages at various stages of the process. These messages indicate warnings or errors encountered during file processing, text extraction, chunk splitting, embedding creation, and question-answering chain execution. Appropriate error messages are returned if any critical issues arise, ensuring proper feedback to the user.

run() Function: 
The main function in this file is the run() function, which takes the uploaded files and user's question as input. It's responsible to orchestrate the necessary steps of file processing, text extraction, chunk splitting, embedding creation, and question-answering chain execution. If any issues occur during the process, it returns informative error messages. Otherwise, it returns the response generated by the question-answering chain.

"""


class FlowCoordinator:
    def __init__(self, param_controller: ParameterController) -> None:
        """Constructor for FlowCoordinator"""
        self.param_controller = param_controller
        
        load_dotenv()
        logging.basicConfig(level=logging.INFO)

        self.file_factory = FileHandlerFactory()
        self.processor = DefaultTextProcessor(param_controller)
        self.runner = QAChainRunner(param_controller)


    def run(self, files: List[IO], user_question: str) -> str:
        """Main function to process uploaded files and user's question, and run the QA chain.
        Args:
            files: List of uploaded files.
            user_question: User's question input.
        Returns:
            str: The response from the QA chain runner.
        """

        # # Set up with the configurations.
        self.runner.setup()

        ## VERIFY THE INPUT BEFORE STARTING WITH THE REST
        is_valid, error_message = self.validate_input(files, user_question)
        if not is_valid:
            return error_message

        ## READ THE FILES > COMBINED TEXT
        combined_text = self.read_files(files)
        if combined_text is None:
            return "No text could be extracted from the provided files. Please try again with different files."

        ## CREATE CHUNKS FROM THE COMBINED TEXT
        chunks = self.chunk_text(combined_text)
        if chunks is None:
            return "Couldn't split the text into chunks. Please try again with different text."

        ## CREATE EMBEDDINGS FOR THE CHUNKS
        knowledge_base = self.create_embeddings(chunks)
        if knowledge_base is None:
            return "Couldn't create embeddings from the text. Please try again."

        ## RATE AND RETRIEVE THE MOST RELATED CHUNKS
        relevant_chunks = self.rate_and_retrieve_chunks(knowledge_base, user_question)
        if relevant_chunks is None:
            return "Couldn't find any relevant chunks for your question. Please try asking a different question."

        ## RUN THE QA CHAIN WITH THE CHUNKS & THE USER QUESTION
        return self.run_qa_chain(relevant_chunks, user_question)























    def validate_input(self, files: List[IO], user_question: str) -> Tuple[bool, str]:
        if files and len(files) > 3:
            logging.warning("Please upload a maximum of 3 files")
            return False, "Please upload a maximum of 3 files"
        if not user_question or not files:
            logging.warning("Both files and user question are required.")
            return False, "Both files and user question are required."
        return True, ""


    def read_files(self, files: List[IO]) -> Optional[str]:
        """
        Reads the files and returns the combined text.
        """
        combined_text = ""
        for file in files:
            if file is not None:
                handler = self.file_factory.get_file_handler(file.type)
                text = handler.read_file(file)
                if not text:
                    logging.error(f"No text could be extracted from {file.name}. Please ensure the file is not encrypted or corrupted.")
                    return None
                else:
                    combined_text += text
        return combined_text

    def chunk_text(self, combined_text: str) -> Optional[List[str]]:
        """
        Takes a combined text and chunks it.
        """
        chunks = self.processor.split_text(combined_text)
        if not chunks:
            logging.warning("Couldn't split the text into chunks. Please try again with different text.")
            return None
        return chunks

    def create_embeddings(self, chunks: List[str]) -> Optional[Dict]:
        """
        Takes chunks and creates embeddings in a knowledge base.
        """
        knowledge_base = self.processor.create_embeddings(chunks)
        if not knowledge_base:
            logging.warning("Couldn't create embeddings from the text. Please try again.")
            return None
        return knowledge_base


    def rate_and_retrieve_chunks(self, knowledge_base: Dict, user_question: str) -> Optional[List[str]]:
        """
        Rates and retrieves the most relevant chunks for the user's question.
        """
        relevant_chunks = self.runner.get_relative_chunks(knowledge_base, user_question)
        if not relevant_chunks:
            logging.warning("Couldn't find any relevant chunks for your question. Please try asking a different question.")
            return None
        return relevant_chunks


    def run_qa_chain(self, relevant_chunks: List[str], user_question: str) -> str:
        """
        Runs the QA chain on the provided documents and user's question.
        """
        return self.runner.run_chain(relevant_chunks, user_question)